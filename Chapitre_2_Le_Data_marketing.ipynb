{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/ytKVKMzf+dGBlC7kjifH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedbenhouad-cell/Chapitre_2_Le-Data-marketing/blob/main/Chapitre_2_Le_Data_marketing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ImSrnfxDulSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exemple d‚Äôapplication 2.1**"
      ],
      "metadata": {
        "id": "0ci--yJoum9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**√âtape 2 Installer Tweepy (Biblioth√®que Python pour Twitter**"
      ],
      "metadata": {
        "id": "ue3olE9Yu1pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tweepy pandas"
      ],
      "metadata": {
        "id": "deRwq-tnu9AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**√âtape 3 Configurer l‚Äôauthentification avec l‚ÄôAPI Twitter**"
      ],
      "metadata": {
        "id": "D3-liLCfvBBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tweepy import Client\n",
        "API_KEY = \"Votre API_KEY\"\n",
        "API_KEY_SECRET = \"Votre API_KEY_SECRET \"\n",
        "ACCESS_TOKEN = \"Votre ACCESS_TOKEN \"\n",
        "ACCESS_TOKEN_SECRET = \"Votre ACCESS_TOKEN_SECRET \"\n",
        "BEARER_TOKEN =\"Votre BEARER_TOKEN \"\n",
        "client = Client(\n",
        "    bearer_token=BEARER_TOKEN,\n",
        "    consumer_key=API_KEY,\n",
        "    consumer_secret=API_KEY_SECRET,\n",
        "    access_token=ACCESS_TOKEN,\n",
        "    access_token_secret=ACCESS_TOKEN_SECRET\n",
        ")\n",
        "me = client.get_me()\n",
        "print(me)"
      ],
      "metadata": {
        "id": "B3PZ9NrxvjNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**√âtape 4 R√©cup√©rer les informations du compte IKEA France**"
      ],
      "metadata": {
        "id": "r2Vaob1lvlT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R√©cup√©rer les infos du compte IKEA France\n",
        "user_info = client.get_user(\n",
        "    username=\"IKEA_France\",\n",
        "    user_fields=[\"description\", \"public_metrics\", \"created_at\"]\n",
        ")\n",
        "\n",
        "user_data = user_info.data  # objet User\n",
        "print(user_info)\n",
        "\n",
        "print(f\"Auteur : {user_data.name} (@{user_data.username})\")\n",
        "print(f\"Description : {user_data.description}\")\n",
        "print(f\"Date de cr√©ation : {user_data.created_at}\")\n",
        "print(f\"Nombre d'abonn√©s : {user_data.public_metrics['followers_count']}\")"
      ],
      "metadata": {
        "id": "N9uwbdfwvqS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**√âtape 5 R√©cup√©rer les tweets**"
      ],
      "metadata": {
        "id": "XV1znK_Gvyh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# R√©cup√©rer les 10 derniers tweets d‚ÄôIKEA France\n",
        "tweets = client.get_users_tweets(\n",
        "    id=user_data.id,\n",
        "    tweet_fields=[\"created_at\", \"public_metrics\"],\n",
        "    max_results=10\n",
        ")\n",
        "if tweets.data:\n",
        "    for tweet in tweets.data:\n",
        "        print(f\"Date : {tweet.created_at}\")\n",
        "        print(f\"Texte : {tweet.text}\")\n",
        "        print(f\"Likes : {tweet.public_metrics['like_count']}\")\n",
        "        print(f\"Retweets : {tweet.public_metrics['retweet_count']}\")\n",
        "        print(f\"R√©ponses : {tweet.public_metrics['reply_count']}\")\n",
        "        print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"Aucun tweet trouv√© pour ce compte.\")"
      ],
      "metadata": {
        "id": "jZzq4RFFv4bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**√âtape 6. Sauvegarder les tweets dans un CSV**"
      ],
      "metadata": {
        "id": "9yv_43vhv9zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# √âtape 6 ‚Äì Sauvegarder dans un CSV\n",
        "import pandas as pd\n",
        "\n",
        "data = []\n",
        "\n",
        "if tweets.data:\n",
        "    for tweet in tweets.data:\n",
        "        data.append({\n",
        "            \"Date\": tweet.created_at,\n",
        "            \"Texte\": tweet.text,\n",
        "            \"Likes\": tweet.public_metrics[\"like_count\"],\n",
        "            \"Retweets\": tweet.public_metrics[\"retweet_count\"],\n",
        "            \"R√©ponses\": tweet.public_metrics[\"reply_count\"]\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(\"ikea_france_tweets.csv\", index=False)\n",
        "    print(\"Les tweets ont √©t√© enregistr√©s dans 'ikea_france_tweets.csv'.\")\n",
        "else:\n",
        "    print(\"Aucun tweet √† enregistrer.\")\n"
      ],
      "metadata": {
        "id": "5jxOx7YxwCqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exemple d‚Äôapplication 2.2**"
      ],
      "metadata": {
        "id": "bqMU45W4xh-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D√©tection des valeurs manquantes**"
      ],
      "metadata": {
        "id": "M2SludXX9HsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Chemin du fichier Excel\n",
        "file_path = \"/content/Exemple_2.1.xlsx\"\n",
        "try:\n",
        "    # Charger le fichier Excel\n",
        "    df = pd.read_excel(file_path)\n",
        "    # Afficher le chemin du fichier utilis√©\n",
        "    print(f\" Fichier s√©lectionn√© : {file_path}\\n\")\n",
        "    # D√©tecter les valeurs manquantes\n",
        "    missing_values = df.isna().sum()\n",
        "    missing_percentage = (df.isna().sum() / len(df)) * 100\n",
        "    # Cr√©er un DataFrame pour afficher les r√©sultats\n",
        "    missing_df = pd.DataFrame({'Valeurs manquantes': missing_values, 'Pourcentage (%)': missing_percentage})\n",
        "    missing_df = missing_df[missing_df['Valeurs manquantes'] > 0]  # Filtrer les colonnes contenant des valeurs manquantes\n",
        "    # S√©lectionner uniquement les lignes contenant des valeurs manquantes\n",
        "    df_missing = df[df.isna().any(axis=1)]\n",
        "    # Afficher le tableau des valeurs manquantes\n",
        "    if not missing_df.empty:\n",
        "        print(\"Tableau des valeurs manquantes :\")\n",
        "        display(missing_df)  # Affiche le tableau des colonnes concern√©es\n",
        "        print(\"\\n Lignes contenant des valeurs manquantes :\")\n",
        "        display(df_missing)  # Affiche les lignes du fichier contenant des valeurs manquantes\n",
        "        # Sauvegarder ces lignes dans un fichier Excel\n",
        "        output_file = \"/content/valeurs_manquantes.xlsx\"\n",
        "        df_missing.to_excel(output_file, index=False)\n",
        "        print(f\"\\n Fichier des valeurs manquantes enregistr√© sous : {output_file}\")\n",
        "    else:\n",
        "        print(\" Aucune valeur manquante d√©tect√©e !\")\n",
        "except FileNotFoundError:\n",
        "    print(f\" Le fichier sp√©cifi√© n'a pas √©t√© trouv√© : {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Une erreur est survenue : {e}\")\n"
      ],
      "metadata": {
        "id": "sl87UQnlxp3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gestion des valeurs manquantes**"
      ],
      "metadata": {
        "id": "gwDdsnc_9Thn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier Excel\n",
        "file_path = \"/content/Exemple_2.1.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Imputation de X3 par la m√©diane\n",
        "col_x3 = \"X3_Montant_achats_promotion\"\n",
        "df[col_x3] = pd.to_numeric(df[col_x3], errors=\"coerce\")   # convertir en num√©rique\n",
        "df[col_x3] = df[col_x3].fillna(df[col_x3].median())       # remplacer NaN par m√©diane\n",
        "\n",
        "# Imputation de X2 par la m√©diane\n",
        "col_x2 = \"X2_Dur√©e_en_magasin_ou_site_heures\"\n",
        "df[col_x2] = pd.to_numeric(df[col_x2], errors=\"coerce\")   # convertir en num√©rique\n",
        "df[col_x2] = df[col_x2].fillna(df[col_x2].median())       # remplacer NaN par m√©diane\n",
        "\n",
        "# Sauvegarder dans un nouveau fichier Excel\n",
        "output_file = \"/content/donnees_imputees.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Fichier sauvegard√© : {output_file}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_6_Z1xvX9ZX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger le fichier Excel\n",
        "file_path = \"/content/Exemple_2.1.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Remplacer les valeurs manquantes de Y par la modalit√© la plus fr√©quente (mode)\n",
        "mode_y = df[\"Y\"].mode(dropna=True)[0]\n",
        "df[\"Y\"] = df[\"Y\"].fillna(mode_y)\n",
        "\n",
        "# Sauvegarder dans un nouveau fichier Excel\n",
        "output_file = \"donnees_imputees_Y.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Valeurs manquantes de Y remplac√©es par la modalit√© la plus fr√©quente : {mode_y}\")\n",
        "print(f\"Fichier sauvegard√© : {output_file}\")\n"
      ],
      "metadata": {
        "id": "MIDx5FxvCg13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Identification et correction des valeurs aberrantes**"
      ],
      "metadata": {
        "id": "dTwLS8voXcFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# √âTAPE 1 ‚Äî Charger le fichier Excel\n",
        "file_path = \"/content/Exemple_2.2.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# √âTAPE 2 ‚Äî D√©finir les variables quantitatives √† analyser\n",
        "cols = [\n",
        "    \"X1_Fr√©quence_d_achat\",\n",
        "    \"X2_Dur√©e_en_magasin_ou_site_heures\",\n",
        "    \"X3_Montant_achats_promotion\",\n",
        "    \"X4_Dur√©e_utilisation_r√©seaux_sociaux_heures\"\n",
        "]\n",
        "# Garder uniquement les colonnes qui existent r√©ellement dans le fichier\n",
        "cols = [c for c in cols if c in df.columns]\n",
        "# Conversion en num√©rique (important pour calculer quantiles/IQR)\n",
        "df[cols] = df[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "# √âTAPE 3 ‚Äî Identification des valeurs aberrantes (m√©thode IQR)\n",
        "# On calcule : Q1, Q3, IQR, borne basse, borne haute, nb d'outliers\n",
        "report = {}\n",
        "for c in cols:\n",
        "    Q1 = df[c].quantile(0.25)\n",
        "    Q3 = df[c].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    borne_basse = Q1 - 1.5 * IQR\n",
        "    borne_haute = Q3 + 1.5 * IQR\n",
        "    masque_outliers = (df[c] < borne_basse) | (df[c] > borne_haute)\n",
        "    nb_outliers = int(masque_outliers.sum())\n",
        "    report[c] = {\n",
        "        \"Q1\": float(Q1),\n",
        "        \"Q3\": float(Q3),\n",
        "        \"IQR\": float(IQR),\n",
        "        \"borne_basse\": float(borne_basse),\n",
        "        \"borne_haute\": float(borne_haute),\n",
        "        \"outliers_avant\": nb_outliers\n",
        "    }\n",
        "print(\" √âTAPE 3 ‚Äî R√©sultats de l‚Äôidentification (m√©thode IQR) :\")\n",
        "for c, info in report.items():\n",
        "    print(\n",
        "        f\"- {c}: {info['outliers_avant']} outliers | \"\n",
        "        f\"Q1={info['Q1']:.2f}, Q3={info['Q3']:.2f}, IQR={info['IQR']:.2f} | \"\n",
        "        f\"Bornes=({info['borne_basse']:.2f} ; {info['borne_haute']:.2f})\"\n",
        "    )\n",
        "\n",
        "# √âTAPE 4 ‚Äî Correction des valeurs aberrantes (winsorisation)\n",
        "# Winsorisation = plafonner les valeurs < borne_basse et > borne_haute\n",
        "for c in cols:\n",
        "    borne_basse = report[c][\"borne_basse\"]\n",
        "    borne_haute = report[c][\"borne_haute\"]\n",
        "    df[c] = df[c].clip(lower=borne_basse, upper=borne_haute)\n",
        "# (Optionnel) Recompter les outliers apr√®s correction (doit √™tre 0)\n",
        "print(\"\\nüìå √âTAPE 4 ‚Äî V√©rification apr√®s winsorisation :\")\n",
        "for c in cols:\n",
        "    borne_basse = report[c][\"borne_basse\"]\n",
        "    borne_haute = report[c][\"borne_haute\"]\n",
        "    masque_outliers_apres = (df[c] < borne_basse) | (df[c] > borne_haute)\n",
        "    print(f\"- {c}: {int(masque_outliers_apres.sum())} outliers apr√®s correction\")\n",
        "# √âTAPE 5 ‚Äî Sauvegarder le fichier corrig√©\n",
        "output_file = \"/content/Exemple_2.2_winsorise.xlsx\"\n",
        "df.to_excel(output_file, index=False)\n",
        "print(f\"\\n Fichier sauvegard√© : {output_file}\")\n"
      ],
      "metadata": {
        "id": "j5Oc9AToXn_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalisation des donn√©es**"
      ],
      "metadata": {
        "id": "rr4BFLWUhCYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importation des biblioth√®ques et Chargement du fichier Excel**"
      ],
      "metadata": {
        "id": "zLSRjnWoh1mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
        "file_path = '/content/Exemple_2.3.xlsx'  # Remplacez par le chemin de votre fichier Excel\n",
        "df = pd.read_excel(file_path, sheet_name=0)  # Charger la premi√®re feuille\n",
        "print(\"Donn√©es Brutes :\\n\", df)"
      ],
      "metadata": {
        "id": "hdirJoqbvQl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Z-Score**"
      ],
      "metadata": {
        "id": "usRWuCRbhTMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifier les colonnes num√©riques\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "# Application de la m√©thode Z-Score\n",
        "z_score_scaler = StandardScaler()\n",
        "df_z_score = df.copy()\n",
        "df_z_score[num_cols] = z_score_scaler.fit_transform(df[num_cols])\n",
        "print(\"\\nZ-Score Scaling :\\n\", df_z_score)\n",
        "# Sauvegarder les r√©sultats dans un fichier Excel\n",
        "output_file = 'Normalisation_Zscore.xlsx'  # Nom du fichier de sortie\n",
        "\n",
        "print(f\"\\nLes r√©sultats ont √©t√© sauvegard√©s dans '{output_file}'.\")\n"
      ],
      "metadata": {
        "id": "JV77NE2cigEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Application du Min-Max Scaling**"
      ],
      "metadata": {
        "id": "TgXk70Gf0Z8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifier les colonnes num√©riques\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Appliquer Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "df_min_max = df.copy()\n",
        "df_min_max[num_cols] = min_max_scaler.fit_transform(df[num_cols])\n",
        "print(\"\\nMin-Max Scaling (0 √† 1) :\\n\", df_min_max)\n",
        "\n",
        "# Sauvegarder les r√©sultats dans un fichier Excel\n",
        "output_file = 'NormalisationMiMax.xlsx'  # Nom du fichier de sortie\n",
        "df_min_max.to_excel(output_file, sheet_name='Min-Max Scaling', index=False)\n",
        "\n",
        "print(f\"\\nLes r√©sultats ont √©t√© sauvegard√©s dans '{output_file}'.\")"
      ],
      "metadata": {
        "id": "LMhMhByf0cIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Application du Scaling entre -1 et 1**"
      ],
      "metadata": {
        "id": "1OoE3xM905PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifier les colonnes num√©riques\n",
        "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "max_abs_scaler = MaxAbsScaler()\n",
        "df_max_abs = df.copy()\n",
        "df_max_abs[num_cols] = max_abs_scaler.fit_transform(df[num_cols])\n",
        "print(\"\\nScaling entre -1 et 1 :\\n\", df_max_abs)\n",
        "# Sauvegarder les r√©sultats dans un fichier Excel\n",
        "output_file = 'Normalisation_Scaling.xlsx'  # Nom du fichier de sortie\n",
        "df_min_max.to_excel(output_file, sheet_name='Min-Max Scaling', index=False)\n",
        "\n",
        "print(f\"\\nLes r√©sultats ont √©t√© sauvegard√©s dans '{output_file}'.\")"
      ],
      "metadata": {
        "id": "vF_k7Quf1H6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bBSdYO1u1Ald"
      }
    }
  ]
}